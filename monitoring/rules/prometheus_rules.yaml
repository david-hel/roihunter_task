apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  generation: 1
  name: prometheus-prometheus-oper-k8s
  namespace: monitoring
spec:
  groups:
  - name: k8s
    rules:
    - alert: KubernetesMemoryPressure
      annotations:
        message: 'Kubernetes memory pressure (instance {{ $labels.instance }})'
      expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
      for: 3m
      labels:
        severity: error
    - alert: KubernetesDiskPressure
      annotations:
        message: 'Kubernetes disk pressure (instance {{ $labels.instance }})'
      expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
      for: 5m
      labels:
        severity: error
    - alert: KubernetesPersistentvolumeclaimPending
      annotations:
        message: 'Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})'
      expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
      for: 5m
      labels:
        severity: warning
    - alert: KubernetesVolumeOutOfDiskSpace
      annotations:
        message: 'Kubernetes Volume out of disk space (instance {{ $labels.instance }})'
      expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
      for: 5m
      labels:
        severity: warning
    - alert: HostOutOfDiskSpace
      annotations:
        message: 'Host out of disk space (instance {{ $labels.instance }})'
      expr: (node_filesystem_avail_bytes{mountpoint="/"}  * 100) / node_filesystem_size_bytes{mountpoint="/"} < 10
      for: 5m
      labels:
        severity: warning
    - alert: KubernetesVolumeFullInFourDays
      annotations:
        message: 'Kubernetes Volume full in four days (instance {{ $labels.instance }})'
        description: "{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}% is available.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
      expr: predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
      for: 5m
      labels:
        severity: warning
    - alert: KubernetesPodNotHealthy
      annotations:
        message: 'Kubernetes Pod not healthy (instance {{ $labels.instance }})'
        description: "Pod has been in a non-ready state for longer than an hour.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
      expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"} == 1)[1h:])
      for: 5m
      labels:
        severity: error
    - alert: KubernetesPodCrashLooping
      annotations:
        message: 'Kubernetes pod crash looping (instance {{ $labels.instance }})'
        description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
      expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 5
      for: 5m
      labels:
        severity: warning
    - alert: KubernetesApiServerErrors
      annotations:
        message: 'Kubernetes API server errors (instance {{ $labels.instance }})'
        description: "Kubernetes API server is experiencing high error rate\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
      expr: sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[2m])) / sum(rate(apiserver_request_count{job="apiserver"}[2m])) * 100 > 3
      for: 5m
      labels:
        severity: error
    - alert: KubernetesDeploymentGenerationMismatch
      annotations:
        message: 'Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})'
        description: "A Deployment has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
      expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
      for: 5m
      labels:
        severity: error
    - alert: HighMemoryUsageofContainer
      annotations:
        message: Container named {{$labels.container}} in {{$labels.pod}} in {{$labels.namespace}} is using more than 80% of Memory Limit
        description: "\nCluster Name: {{$externalLabels.cluster}}\nNamespace: {{$labels.namespace}}\nPod name: {{$labels.pod}}\nContainer name: {{$labels.container}}\n"
      expr: ((( sum(container_memory_working_set_bytes{image!="",container!="POD", namespace!="kube-system"}) by (namespace,container,pod)  /  sum(container_spec_memory_limit_bytes{image!="",container!="POD",namespace!="kube-system"}) by (namespace,container,pod) ) * 100 ) < +Inf ) > 80
      for: 5m
      labels:
        severity: error
    - alert: HighCpuUsageofContainer
      annotations:
        message: Container named {{$labels.container}} in {{$labels.pod}} in {{$labels.namespace}} is using more than 80% of CPU
        description: "Container CPU usage is above 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
      expr: (sum by(namespace, pod) (rate(container_cpu_usage_seconds_total{image!="", container!="POD"}[3m])) * 100 ) > 80
      for: 5m
      labels:
        severity: error
    - alert: HPAScalingLimited
      annotations:
        message: HPA named {{$labels.hpa}} in {{$labels.namespace}} namespace has reached scaling limited state
        description: "\nCluster Name: {{$externalLabels.cluster}}\nNamespace:{{$labels.namespace}}\nHPA name: {{$labels.hpa}}\n"
      expr: (sum(kube_horizontalpodautoscaler_status_condition{condition="ScalingLimited",status="true"}) by (horizontalpodautoscaler,namespace)) == 1
      for: 1m
      labels:
        severity: error
    - alert: HPAatMaxCapacity
      annotations:
        message: HPA named {{$labels.hpa}} in {{$labels.namespace}} namespace has reached scaling limited state
        description: "\nCluster Name: {{$externalLabels.cluster}}\nNamespace: {{$labels.namespace}}\nHPA name: {{$labels.hpa}}\n"
      expr: ((sum(kube_horizontalpodautoscaler_spec_max_replicas) by (horizontalpodautoscaler,namespace)) - (sum(kube_horizontalpodautoscaler_status_current_replicas) by (horizontalpodautoscaler,namespace))) == 0
      for: 1m
      labels:
        severity: error